---
title: "COMPSCIX 415.2 Homework 9/Final"
author: "Chi Nguyen"
date: "3/26/2019"
output:
  html_document:
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

My Github repository for my assignments can be found at this URL: https://github.com/chimandy/compscix-415-2-assignments.git

```{r}
library(mdsr)
library(tidyverse)
library(broom)
library(ggplot2)
```

Sampling distributions and standard error
Functions and loops
AB testing
Linear regression

#Exercises (Total Points - 20)

##Exercise 1 - Sampling Distributions, Functions and For Loops (10 points)
Recall that the distribution of the sample mean is approximately a Normal distribution, and that the standard error is σn√. This holds true regardless of the distribution of our population.

For this problem, assume that the number of miles that a particular car can run before its battery wears out is exponentially distributed with an average of 10,000 miles. The exponential distribution looks like this:

The exponential distribution has a rate parameter that controls how quickly the distribution decays and defines what the mean and standard deviation will be. In our case the rate = 1/10000, the mean = 10000 and the standard deviation = 10000. You can sample from this exponential distribution in R using this code:

```{r}
# sample size
samp_size <- 100
# set the rate parameter
samp_rate <- 1/10000

# take sample
rexp(n = samp_size, rate = samp_rate)
```

###*Step 1*

Write an R function that does the following:

-Takes a sample of size samp_size from this exponential distribution (samp_size is an input parameter for the function)
-Calculates the mean of that sample
-Calculates the standard deviation of that sample
-Returns the calculated mean and standard deviation as a list
Helper code

```{r}
samp_fun <- function(samp_size, samp_rate) {
  df<-rexp(n = samp_size, rate = samp_rate)
  samp_avg<-mean(df)
  samp_std_dev<-sd(df)
  stats <- list(samp_avg = samp_avg, samp_std_dev = samp_std_dev)
  return(stats)
}
samp_fun(samp_size,samp_rate)
samp_result<-samp_fun(samp_size,samp_rate)
```


###*Step 2*

Then write a loop that does this:

Runs the above function 1000 times, with  samp_size = 50 and samp_rate = 1/10000
Saves all of the sample means in a vector called  sample_means, and all of the sample standard deviations in a vector called sample_sds


```{r}
n <-1000#how many samples
sample_means<-rep(NA,n)
sample_sds<-rep(NA,n)
for(i in 1:n){ 
  my_result<-samp_fun(50,1/10000)
  sample_means[i]<-my_result$samp_avg
  sample_sds[i]<-my_result$samp_std_dev
}
all_results<-tibble(sample_means,sample_sds)
all_results
```


###*Step 3*
-Then plot your sample means as a histogram
-output the standard deviation of your sample means 
-calculate the theoretical standard error (σ=10000, n = sample size)
-calculate the mean of the sample standard deviations and use this to calculate the empirical standard error

*Plot sample_means*

```{r}
sample_means_df<-data.frame(sample_means)
sample_means_df %>% ggplot()+
  geom_histogram(aes(x=sample_means))
```




*Output standard deviation for sample_means*

```{r}
sample_means_std<-sd(sample_means_df$sample_means)
sample_means_std
```

*Calculate the theoretical standard error (σ=10000, n = sample size)*

```{r}

theoratical_sd<-10000/sqrt(50)
theoratical_sd

```

*Calculate the mean of the sample standard deviations and use this to calculate the empirical standard error*

```{r}
sample_sds_df<-data.frame(sample_sds)
mean_sample_sds<-mean(sample_sds_df$sample_sds)
emprical_sd<-mean_sample_sds/sqrt(50)
emprical_sd
```

###*Step 4*

Repeat STEP 2 and STEP 3 using a sample size of  5000.


```{r}
n <-1000#how many samples
sample_means<-rep(NA,n)
sample_sds<-rep(NA,n)
for(i in 1:n){ 
  my_result<-samp_fun(5000,1/10000)
  sample_means[i]<-my_result$samp_avg
  sample_sds[i]<-my_result$samp_std_dev
}
all_results<-tibble(sample_means,sample_sds)
all_results
```
```{r}
sample_means_df<-data.frame(sample_means)
sample_means_df
sample_means_df %>% ggplot()+
  geom_histogram(aes(x=sample_means))
```

```{r}
sample_means_std<-sd(sample_means_df$sample_means)
sample_means_std
```
```{r}
theoratical_sd<-10000/sqrt(5000)
theoratical_sd
```

```{r}
sample_sds_df<-data.frame(sample_sds)
mean_sample_sds<-mean(sample_sds_df$sample_sds)
emprical_sd<-mean_sample_sds/sqrt(5000)
emprical_sd
```



##Exercise 2 - Linear Regression (5 points)
For this exercise we will return to the House Prices prediction dataset that we used for HW 7. You should have already downloaded the train.csv dataset before, but if you didn’t you can download it from Canvas in this week’s module.

Load the train.csv dataset into R and fit a regression model with:

y = SalePrice
Features: LotArea, OverallQual, and  ExterQual
Answer these questions:

-Use the broom package to output the coefficients and the R-squared
-Interpret the coefficient on LotArea
-Interpret the coefficient on ExterQualGd
-Compare this model to the model we fit in HW 7 with GrLivArea, OverallQual,  Neighborhood. Which is the better fitting model?

*Use the broom package to output the coefficients and the R-squared*
```{r}
file_path<-'train.csv'
train_data<- read_csv(file='train.csv')
```


```{r}
train_mult_lm_2 <- lm(formula=SalePrice ~ LotArea + OverallQual + ExterQual, data = train_data)
tidy(train_mult_lm_2)
```

```{r}
glance(train_mult_lm_2)
summary(train_mult_lm_2)
```

*Interpret the coefficient on LotArea*
LotArea: Lot size in square feet

For every extra square foot of lot area, the sale price increases, on average, $1.45 , with all other features being held constant. 
For this model, for every one unit increae in the overall quality of the lot area, the mean increase in the sale price is $34466. 

*Interpret the coefficient on ExterQualGd*
ExterQual: Evaluates the quality of the material on the exterior

       Ex	Excellent
       Gd	Good
       TA	Average/Typical
       Fa	Fair
       Po	Poor
       
the negative coeeficient on ExterQualGd states that if the quality of the material on exterior is good graded but not excellent, the price difference will be -$71,529 compared to the excellent graded. 

*Compare this model to the model we fit in HW 7 with GrLivArea, OverallQual,  Neighborhood. Which is the better fitting model?*

The previous R-squared from HW7 is (.78), which is larger than R-Squared from this model (0.695). As a result, the previous model we fit in WH 7 with GrLivArea, OverallQual,  Neighborhood is better fitting model.

##Exercise 3 - AB Testing (5 points)*
Download the ab_test_data.csv file from Canvas. This file contains two columns: version and  conversion. Each row is a visitor to a webpage. The  version column tells us which version of the webpage the visitor saw, and the conversion column is a binary value and equals 1 if the visitor converted (0 otherwise).

```{r}
df <- read.table("ab_test_data.csv", header=TRUE, 
   sep=",")
glimpse(df)
df
```

We want to perform an AB test on this data to see if the conversion rates are different for the two versions of the webpage.

Answer these questions:

####a.What proportion of visitors converted for each version of the webpage?

*Proportion of vistors converted for version A*
```{r}
number_A<-df%>%filter(version=='A')%>%count()
number_A_converted<-df%>%filter(conversion==1)%>%filter(version=='A')%>%count()
proportion_A_converted<-number_A_converted/number_A
true_a<-proportion_A_converted
true_a<-true_a[[1]]
true_a
```

*Proportion of vistors converted for version B*

```{r}
number_B<-df%>%filter(version=='B')%>%count()
number_B_converted<-df%>%filter(conversion==1)%>%filter(version=='B')%>%count()
proportion_B_converted<-number_B_converted/number_A
true_b<-proportion_B_converted
true_b<-true_b[[1]]
true_b
```


####b.Perform the AB test in R. What is the p-value for the AB test (hypothesis test of proportions)?

```{r}
n_a =number_A[[1]]
n_b =number_B[[1]]
set.seed(10)
samp_a <-rbinom(n = 1, size = n_a, prob = true_a)
samp_b <-rbinom(n = 1, size = n_b, prob = true_b)
samp_a
samp_b

```


```{r}

two_prop_test <- prop.test(c(samp_a, samp_b), c(n_a, n_b))
two_prop_test$p.value
```


The p-value,which is smaller than 0.05, tells us that the conversion rates for Version A and B are significantly different than each other, so we'd conclude here that whatever changes were made to the webpage did have an effect.